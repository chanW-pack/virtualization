# VMware vSphere 가상화 기초 지식

## vSphere CPU 가상화 동작의 개요

vSphere의 하이퍼바이저, 즉 **ESXi에서는 물리적인 CPU를 가상화하여 가상머신에 할당**할 수 있다.

특징은 다음과 같다.

1. **물리 서버에 존재하는 복수의 논리 CUP의 부하를 동적으로 로드밸런싱**
    
    물리 CPU는 소켓 단위로 존재하는데 소켓은 다시 코어로 나누어진다. (CPU > 소켓 > 코어)
    
    일반적인 PC에서는 CPU 1개, 즉 1개의 소켓만 있는 것이 대부분인데, 전산센터에서 가장 많이 사용하는 x86 1U 서버에는 기본적으로 2개의 소켓이 탑재된다.
    
    (소켓은 흔히 코어라고 하는 작은 연산회로로 나누어짐)
    
    서버용 CPU는 적게는 쿼드코어부터 많게는 16코어까지 지원하는 제품이 출시되고 있다
    
    (2 소켓의 CPU라면 최대 32코어까지 제공하는 것)
    
    여기에 코어를 다시 쓰레드 형태로 쪼개는 하이퍼스레드까지 지우너하면 64 스레드까지 지원하는 엄청난 리소스가 됨
    
    이런 리소스들을 ESXi는 가상 CPU로 할당함
    
    이때 여러 대의 가상머신에 할당되는 CPU는 물리적은 CPU의 리소스를 사용하게 되는데 여러 대의 가상머신들이 물리적인 CPU의 코어를 할당받을 수 있음
    
    이런 경우 물리적인 CPU, 코어의 리소르르 ESXi 서버가 실시간으로 여러 대의 가상머신에 동적으로 분배함
    
    **이를 CPU 리소스 로드밸런싱이라고 함**
    
2. **가상머신이 사용하는 CPU 리소스를 동적으로 분배하여 특정 CPU에 부하가 집중되는것을 방지**
- ESXi  서버는 동적으로 물리적인 CPU 미 논리적인 가상 CPU에 대해 모니터링을 실시함
- 이때 모든 가상머신에서 발생하는 프로세스들은 물리적은 CPU에 공통으로 분배해서 할당하여 처리함
- 만약 전체 물리적 리소스에 과도한 부하가 발생한다면 ESXi 서버는 시분할 방식을 통해 프로세스를 처리하도록 하여 한 대의 가상머신에 부하가 집중되는 것을 방지함

1. **수십 밀리 세컨드 단위로 전체의 CPU를 체크하여 가상머신의 워크로드를 이동**
- ESXi 서버는 몇십 ms단위로 물리적인 CPU의 상태를 체크하면서 여유가 있는 CPU 리소스를 확인한 다음 전체 가상머신에 골고루 할당

---

## vSphere 메모리 가상화 기술 개요

vSphere는 물리적인 서버의 메모리를 가상화로 전환했을 때 효율적으로 운용하기 위해 네 가지의 메모리 가상화 기술을 제공한다.

이를 통해 전체 가상머신의 메모리 총합이 **물리적인 서버의 메모리량을 초과하더라도 가상머신의 전원을 구동 가능하도록 하는 메모리 오버커밋 (Over Commit) 기능을 제공**한다.

- 투명한 페이지 공유 기술과 메모리 별루닝 기술은 메모리를 효율적으로 관리하기 위한 기술
- 메모리 압축 기술과 VMkernel 스왑 기술은 시스템을 보호하기 위한 기술이다.

### NUMA (Non-Uniform Memory Access)

CPU가 1개이며 코어가 1개밖에 없던 시절에는 구조가 매우 단순했기 때문에 CPU와 Memory가 1:1의 액세스 구조를 가질 수 있었다

하지만 최근의 서버에는 하나의 CPU만 탑재되는 것이 아니라 여러 개의 CPU가 탑재될 수 있다.

이런 것을 SMP (Symmeric Multi Processing)이라고 부른다.

이 환경에서는 여러 개의 CPU가 공통의 Memory를 액세스하기 때문에 메모리를 어디에서 액세스할 것인지가 매우 중요하다.

이런 부분을 해결하기 위해 나온 것이 NUMA이다. NUMA는 CPU코어와 메모리를 그룹 형태로 묶어서 액세스하도록 처리하는 구조이다.

즉, 각 CPU에 독립적인 Memory를 제공하여 SMP 구조에서의 병목을 줄이겠다는 것. 물론 이렇게 한다고 해서 CPU에서 FIx해서 할당하는 것은 아니고 다른 쪽의 메모리도 사용할 수 있도록 어느 정도의 유연성은 자동으로 주는 편이다.

1. **투명한 페이지 공유**
- 게스트 OS의 시스템 영역 등, 가상머신 사이에서 동일한 정적 페이지를 공유하는 기능이다.
- 여러 대의 가상 머신이 하나의 물리적인 서버 안에서 운용될 때 동일한 종류의 가상머신일 경우 같은 페이지를 사용하기도 한다.
- 가상 머신은 메모리를 자기 자신만 사용하고 있다고 착각한다.
- 하지만 하이퍼바이저 입장에서 본다면 동일한 게스트 OS의 동일한 페이지가 각 가상머신마다 있기 때문에 이런 동알한 가상 페이지를 물리적은 하드웨어의 같은 페이지를 참조하도록 설정한다.

1. **메모리 벌루닝 (Memory Ballooning)**
- 동작을 멈추고 있는 (Idle) 상태의 가상 머신이 보유하고 있는 메모리 영역을 회수하여, 다른 가상머신에게 할당해 주는 기능
- 가상머신이 바쁘게 돌아가는 경우에 게스트 OS는 가상머신의 메모리를 일부 점유해서 사용한다.
- 일반적인 물리서버에 OS가 하나라면 얼마든지 메모리를 상주시켜 놓고 사용해도 된다.
- 하지만 여러 대의 가상머신이 구동되는 경우에는 가상머신의 사용하지 않는 메모리를 모니터링하고 있다가 사용하지 않는 메모리 영역을 회수한다.
- 이는 다른 가상머신에게 메모리가 모자라 하이퍼바이저에 요구할 때 발생한다.

- 하이퍼바이저 (실제로는 VMkernel)는 현재 Active 하게 동작하고 있지 않는 가상머신에 대해 벌루닝 작업을 한다.
- 가상머신의 메모리 공간에 실제 메모리를 전체 사용하는 것처럼 조작한다.
- 이는 가상머신에 설치되어 있는 VMware Tool의 Driver를 통해 이루어진다.
- 명령을 받은 가상머신은 자신의 메모리가 가득 찬 것처럼 착각하여 가상머신의 메모리를 Swap Out 시킨다.
- 기존 물리적인 서버에서는 디스크에 스왑을 했겠지만 가상머신에서는 메모리로 Swap Out되는 것
- 가상머신에게는 디스크 Swap Out 하는 것처럼 착각하게 만드는 것
- 이를 통해 가상머신의 메모리를 회수하여 Busy한 가상머신에 할당함

1. **메모리 압축**
- 메모리 데이터를 압축하여 VMkernel 스왑을 줄이고 퍼포먼스 저하를 방지하는 기능
- 이 기능은 메모리에 동일한 데이터가 있다면 동일한 데이터를 메모리 안에서 압축하는 기능
- 이 기능은 가상머신에 메모리 요구가 발생하고 메모리를 회수할 수 없는 상황이 되었을 경우 발생함
- 가상 머신들 중에서도 우선순위가 낮은 가상머신들의 메모리 영역을 압축해서 물리 메모리의 Compression Cache(압축 캐시)에 저장함
- 이를 통해 회수된 영역은 메모리가 모자란 가상머신에 할당됨
- 압축된 영역에 액세스할 때는 물리 메모리 상에서 압축을 풀면서 접근해야하기 때문에 아주 약간의 성능저하가 있을 수도 있지만, 이것은 메모리 내에서 이루어지기 때문에 크게 영향을 주는 정도는 아님

1. **VMkernel 스왑**
- 물리 메모리가 부족한 경우, VMkernel은 가상머신의 메모리를 디스크의 스왑파일에 스왑 아웃함
- 위에서 언급했던 벌루닝은 가상머신이 메모리에 Swap out 하는 기능임
- 하지만 VMkernel 스왑은 실제 하이퍼바이저에서 모든 가상머신이 Busy하여 메모리를 실제로 하드디스크로 Swap Out 할 때 발생하는 현상임
- 메모리에 있는 내용을 디스크로 Swap Out 하는 것이기 때문에 성능에 영향을 미침
- 가능하면 하이퍼바이저는 이런 형태의 Swap out을 방지하기 위해 앞서 언급했던 모든 기능을 총동원함
- 하지만 앞의 3가지 기능이 모두 힘든 상황이라면 어쩔 수 없이 Swap을 발생시켜 디스크로 메모리의 내용을 Swap out 시킴

---

## 스토리지 가상화의 핵심 기술

업계에서 보는 스토리지의 가상화는 하드웨어 방식과 소프트웨어 방식으로 나눌 수 있음

하드웨어 방식은 각 스토리지 하드웨어 벤더가 제공함

스토리지 하드웨어 내부에 있는 컨트롤러 등을 통해 이기종 스토리지를 가상화하는 방식임

기존의 물리적인 디스크를 가상화 환경에서 논리적으로 보이도록 하는 것이 VMware의 스토리지 차에서의 가상화임

반면 스토리지 벤더 차원에서의 스토리지 가상화는 이기종 스토리지들을 하나의 뷰 차원에서 관리하는 것을 말함

### RAID 기술

raid의 개념과 종류는 리눅스 학습 파트 및 개인 동기화 내용에서 확인 가능합니다^^

RAID 학습 ([https://www.notion.so/22-04-22-RAID-457c0ad9dd304952bdd4de009b06b109](https://www.notion.so/22-04-22-RAID-457c0ad9dd304952bdd4de009b06b109))
리눅스파트올려야댐...

### 스토리지 연결 방식 - DAS, NAS, SAN

1. **DAS (Direct Attached Storage)**
- 서버와 스토리지가 직접 연결되는 방식임
- 네트워크 상의 다른 서버는 저장된 데이터에 액세스할 수 없음
- 서버와 스토리지는 FC (Fibre Channel) 케이블로 직접 연결됨

1. **NAS (Network Attached Storage)**
- NAS는 네트워크로 저장소의 연결하는 방식
- 여러 컴퓨터가 동일한 저장소 공간을 공유할 수 있음
- 하드디스크를 중앙에서 관리할 수 있어서 오버헤드가 작게 걸림
- 구축이 용이하며 상대적으로 저렴함
- NFS 같은 프로토콜을 통해 접속할 수 있음

1. **SAN (Storage Area Network)**
- 디스크 어레이 (외장 스토리지) 컨트롤러 및 테이프 라이브러리와 같은 컴퓨터 스토리지 디바이스를 서버와 연결하기 위해 설계된 방식
- 컴퓨터 시스템과 스위치 사이에서 데이터를 전송함
- 스위치는 일반 네트워크 스위치가 아닌 SAN 방식을 지원하는 FC 스위치임
- 흔히 FC 케이블이라는 전용 케이블을 사용하여 서버와 스토리지 그리고 FC 스위치를 연결하여 FC 데이터 통신을 함
- 고가이며 구축이 까다로운 편임

---

## VMware에서 지원하는 전송 방식

프로토콜은 전송 방식의 규악임

프로토콜의 종류에 따라 속도 및 접속 방식이 달라짐

VMware에서는 크게 4가지 프로토콜을 통한 전송 방식을 지원 (FC, iSCSI, FCoE, NFS)

1. **FC (Fibre Channel)**
- 일반적으로 기업 내부에서 SAN을 구축할 경우 가장 많이 사용되는 통신 방식임
- 흔히 FC SAN이라고 부름
- FC SAN은 서버 및 vSphere의 하이퍼바이저인 ESXi 호스트를 고성능 스토리지에 연결하는 특수한 고속의 네트워크임
- 이 네트워크는 Fivre Channel 프로토콜을 통해 SCSI 트래픽을 가상 시스템에서 FC SAN 장비들로 전송함
- FC SAN 에 연결하기 위해서는 호스트에 HBA (Host Bus Adapter)라고 부르는 장비가 설치되어 있어야 함
- 네트워크 통신을 하기 위해 NIC (Network Interface Card)가 필요하듯이 FC 통신을 하기 위해서는 물리적인 서버에 HBA 카드가 장착되어야 함
- 위에서 서버와 스토리지를 직접 연결하는 방식을 DAS 방식이라고 했지만 스토리지에서 나올 수 있는 FC 포트 개수는 정해져 있음
- 일반적으로 기업에서는 한 대의 엔터프라이즈급 스토리지에서 수많은 서버들을 연결하여 데이터를 저장해야 하는데 DAS 방식이라면 슽오리지의 FC 포트 수는 정해져 있으므로 몇 대만 접속이 가능함
- 하지만 FC 방식에도 스위치가 존재함
- 이런 스위치를 통해 서버와 스토리지가 접속되며 DAS 방식이 아니더라도 FC 스위치에서 여러 대의 서버와 스토리지가 FC 프로토콜을 통해 데이터를 주고 받음
- 이런 형태가 SAN (Storage Area Network) 방식임

**!! LUN**

- LUN은 Logical Unit Number의 약자임
- SCSI 방식에서 논리적으로 사용되는 고유 식별자 번호를 말함
- 일반적으로 스토리지에서 많이 사용되는 용어로서 호스트, 즉 서버가 외장형 스토리지에 접근하는 단위로 많이 사용됨
- 외장형 스토리지 어레이 장치는 서버에게 LUN 단위의 논리 디스크를 제공함
- 실무에서는 위에서 배웠던 RAID를 스토리지 어레이 장치에서 생성하고 (RAID 그룹) 이렇게 생성된 RAID 그룹에서 다시 LUN을 생성함
- 이렇게 생성된 LUN을 SAN Switch 등을 통해 호스트에 액세스 가능하도록 제공함

1. **iSCSI (Internet SCSI)**
- FC가 별도의 SAN 네트워크를 구축하는 형태였다면, iSCSI는 일반적으로 사용하는 기존 네트워크를 통해 스토리지를 연결하는 방식임
- SAN 방식에서는 서로의 장비를 연결하기 위해 FC Cable이라는 특수한 케이블을 사용함
- 하지만 iSCSi 는 일반적인 RJ45 방식의 네트워크 케이블로 연결한 다음 네트워크 통신을 통해 SCSI 스토리지 트래픽을 TCP/IP 프로토콜로 패키징해서 전송하는 방식임
- iSCSI 연결에서 ESXi 호스트는 네트워크 상에 있는 iSCSI 스토리지 시스템과 통신하는 이니시에이터(개시) 역할을 수행함
- 또한 iSCSI 스토리지는 타켓(Target)이라고 부름

ESXi 호스트에서 지원하는 iSCSI 연결 방식은 다음의 두 가지임

1. 하드웨어 iSCSI
- ESXi 호스트가 iSCSI 및 네트워크 처리를 오프로드 할 수 있는 별도의 어댑터를 통해 스토리지에 연결됨
- iSCSI HBA를 서버에 별도로 장착 필요

1. 소프트웨어 iSCSI
- ESXI 호스트가 VMkernel에 있는 소프트웨어 기반의 이니시에이터 프로그램을 사용하여 스토리지에 연결함
- vCenter 에서 Enable 하여 활성화할 수 있음
- 대부분의 최신 서버에서는 기본적으로 지원

1. **FCoE (Fibre Channel over Ethernet)**
- SAN 방식이 FC Cable을 통해 별도의 SAN 네트워크를 구성하는 방식이었다면, FCoE 방식은 네트워크를 통해 Fibre Channel 프로토콜을 전송하는 방식임
- 별도의 SAN 네트워크를 위한 장비가 필요하지 않으며 고속의 네트워크만 주어진다면 기존 네트워크 라인을 통해서도 SAN 형태의 스토리지를 연결할 수 있는 방식임
- 하지만 대부분 10G 네트워크 라인을 전제로 하며 안정적인 FCoE 연결을 위한 별도 스위치로 연결하는 방식이 대세로 자리잡고 있음
- iSCSI와 마찬가지로 일반 네트워크를 위한 연결 방식도 동일하게 지원하고 있음

1. 하드웨어 FCoE
- ESXi 호스트가 VMkernel에 있는 소프트웨어 기반의 FCoE 연결 프로그램을 사용하여 스토리지에 연결함
- vCenter에서 Enable하여 활성화 할 수 있음
- 대부분의 최신 서버는 기본적으로 지원

1. **NFS (Network File System)**
- NAS 방식으로 연결할 경우 NFS 프로토콜을 통해 스토리지에 접속함
- ESXi 호스트는 표준 TCP/IP 네트워크를 통해 원격 파일 서버에 연결하여 가상 머신 및 데이터를 저장함
- ESXi 호스트에 NFS 클라이언트가 기본으로 제공됨
- NFS 프로토콜은 버전 3 및 4.1 을 사용하며 NAS 및 NFS 서버와 통신함
- 네트워크 연결이므로 별도의 HBA 같은 장치가 필요치 않으며 서버에서 제공하는 네트워크 라인을 통해 NAS 장비에 접속할 수 있음
- 이 구성에서는 VMFS와 같은 데이터스토어를 생성하는 것이 아니라 NFS 영역에 가상 머신 및 데이터를 직접 저장함

---

## VMware의 (논리) 스토리지 가상화 방식

ESXi 호스트에서 여러 가지 프로토콜 (FC, iSCSI, FCoE, NAS) 을 통해 스토리지 어레이의 LUN을 인식한 후에는 VMware에서 인식할 수 있는 파일 포맷으로 LUN을 포맷함

즉, LUN을 VMware의 파일시스템으로 포맷함

이렇게 VMware의 파일시스템으로 포맷된 것을 VMware에서는 데이터스토어 라고 부름

그리고 그 파일시스템을 VMFS (Virtual Machine File System)이라고 함

VMFS는 퍼포먼스 중심의 VMware 전용 클러스터 시스템임

이 VMFS 파일시스템으로 포맷된 데이터스토어에 가상머신 즉, Virtual Machine이 저장됨

- SAN 방식의 경우 여러 대의 ESXi 호스트가 FC 스위치를 통해 스토리지를 접속함
- VMware는 각 ESXi 호스트를 여러 대로 묶는 클러스터링을 구성할 수 있음
- 클러스터링 구성을 통해 여러 대의 ESXi 호스트가 동일한 스토리지 볼륨(LUN)에 액세스 할 수 있음
- 이는 ESXi 에서 배타적인 lock 관리가 가능하기 때문임
- 일반적인 OS는 동시에 동일한 스토리지 볼륨을 볼 수 있는 배타적인 Lock 관리가 불가능함
- 별도의 솔루션의 도움을 받아야 함 (대표적인 예가 Oracle의 RAC  솔루션임)
- 혹은 OS 차원에서 클러스터링을 구현한다면 Failover Clustering과 같은 솔류션이 있음
- 하지만 VMware에는 배타적인 lock 관리 솔루션이 내장되어 있으므로 별도 솔루션의 도움 없이 ESXi 호스트가 동시에 여러 개의 스토리지 볼륨을 액세스하도록 제어할 수 있음
- 이 경우 가상머신에서 발생하는 SCSI 커맨드는 물리 스토리지에 직접 발행하게 됨
- 현재 VMFS의 버전은 VMFS-5임
- 최대 64TB까지의 용량을 지원할 수 있음
- 가상머신의 디스크는 VMFS 상에서 파일로 존재함
- VMware상에서 가상 디스크 VMDK의 최대 용량은 62TB임
- VMware에서 제공하는 가상 디스크의 방식에는 VMDK와 RDM 방식이 있음
- VMDK는 VMware에서 제공하는 전형적인 가상 디스크임
- VMFS안에 파일 형태로 직접 저장됨
- 이에 반해 RDM은 가상머신이 실제 LUN에 액세스해야 할 필요가 있을 경우 사용함
- 이때 RDM은 가상머신과 물리 LUN을 연결하는 주소, 즉 포인터라고 생각하면 됨
- RDM은 다시 물리 RDM 방식과 가상 RDM으로 나뉘어짐
- 물리 RDM 방식은 최대 64TB까지 지원이 가능하며 가상 RDM은 62TB까지 지원 가능함

---

## 네트워크 가상화의 핵심 기술

## vSphere 가상 네트워크 기초

- 전체적인 구성 개요

1. **가상머신**
- 가상 네트워크 디바이스를 통해서 액세스를 요구함

1. **가상 NIC**
- VMkernel과 가상머신 사이에 위치하여 네트워크 패킷을 전송하거나 수신하는 부분을 담당함
- 가상 NIC은 IP 및 MAC 주소를 가질 수 있음

1. **가상 스위치**
- vSphere 가상 네트워크 환경에서 핵심적인 역할을 수행하는 부분임
- 네트워크 I/O의 에뮬레이션을 담당함
- 가상머신 및 VMkernel용의 포트 그룹을 설정함
- vSphere에서의 가상 스위치는 표준 가상 스위치와 분산 가상 스위치, 두 가지 형태가 존재함
- 역할과 기능이 각 스위치별로 차이가 있음

1. **포트 그룹**
- vSphere에서 중요한 개념임
- 포트 그룹은 VMkernel이나 VM들에 특화된 서비스를 제공하는 가상 스위치의 논리적인 그룹임
- 가상 스위치는 하나의 VMkernel 포트나 가상머신 포트 그룹을 가질 수 있음

 b.  **VMkernel 포트 그룹**

- 하이퍼바이저 관리 트래픽, vMotion, HA, FT, iSCSI 스토리지 연결, VSAN, NAS 연결 등의 다양한 구성을 만드는 특화된 포트 그룹
- vSphere가 가진 특화된 기능들을 구성하기 위해서는 반드시 VMkernel 포트 그룹을 통해 별도의 트래픽을 전송하도록 구성해야 함

 c. **VM 포트 그룹**

- VM들이 동일한 포트 그룹이나 무리 네트워크에 구성된 다른 가상머신에 접근할 수 있게 해주는 가상 스위치 안의 포트 그룹임

1. **물리 NIC**
- vSphere 가상화 환경에서 물리 NIC 은 어떤 역할도 수행하지 않음
- 가상 환경이 아닌 일반적인 구성에서는 물리 NIC에 IP 및 MAC 주소가 할당되지만 가상 환경에서는 IP 및 MAC 을 가지지 않음
- 앞서 언급한 대로 MAC 주소는 가상머신의 가상 NIC에 할당됨

1. **물리 스위치**
- 물리 네트워크 환경을 제공하는 스위치 장비임
- 고객이 보유한 스위치 장비라고 보면 됨
- ESXi 서버는 네트워크 라인을 통해 고객의 네트워크 스위치 장비에 연결됨
- 만약 물리적인 스위치에 VLAN 구성이 되어 있다면 vSphere 가상 네트워크 환경에서도 VLAN 설정을 해줘야 함

---

## vSphere 가상 네트워크 스위치의 특징

1. **물리 NIC은 IP Address를 가지지 않음**
- IP 주소 및 MAC 주소는 모두 가상머신에서 가지고 있음
- 물리 NIC를 네트워크 케이블 연결과 같은 개념이라고 생각하면 쉬움 (가상 스위치와 물리 스위치를 연결하는 케이블)

1. **가상 스위치는 Path-Through의 역할을 수행함**
- 가상 스위치는 네트워크 패킷을 통과시키는 Path-Through의 역할을 수행하는 Edge 스위치라고 생각하면 됨
- 물리 NIC를 통해 내부로 들어온 네트워크 패킷은 가상 스위치를 통해 가상머신에 전달됨
- 이때 가상 스위치와 물리 스위치는 물리 NIC라는 케이블로 연결되어 있다고 생각하면 됨
- 스위치이므로 VLAN 설정도 가능하고, Link aggregation 설정도 가능함

물리적인 스위치와 비교하여 가상 스위치에는 다음과 같은 차이점이 있음

1. **Telnet과 같은 접속을 통해 가상 스위치를 조작할 수 없음**

즉, 커맨드를 통해 관리하는 형태가 아닌 vCenter의 GUI를 통한 조작만 가능함

1. **내부적으로 생성되는 가상 스위치들은 서로 연결될 일이 없기 때문에 루프 현상에 빠질 일이 없음**

그래서 가상 스위치 환경에서는 복잡하게 STP를 위한 설정을 할 필요가 없음

1. **연결되어 있는 VM의 MAC 주소를 이미 알고 있기 때문에 MAC 주소를 학습할 필요가 없음**

가상화 환경에서 VLAN은 중요한 역할을 수행함

트래픽이 동일한 물린 VLAN 세그먼트나 동일한 물리 스위치를 공유하면서 트래픽을 효율적으로 분리하며, 브로드캐스트를 나눠주는 역할을 함

또한, 특정 VLAN에 속하는 트래픽 구별을 위해 태깅(tagging)을 지원하기 위해 IEEE 802.1Q 표준을 지원함

VLAN ID인 VLAN 태그는 1~4094까지를 지원하며 이는 네트워크에서 유일한 VLAN으로 식별됨

---
